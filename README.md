# Machine Learning in Linguistics and Speech Recognition

This project explores the intersection of machine learning and linguistics, focusing on applications in speech recognition systems. The goal was to evaluate how statistical and deep learning models can process human language, with an emphasis on both phonetic/linguistic structures and computational efficiency.  

The research examines the effectiveness of traditional approaches (HMMs, n-grams) alongside modern deep learning methods (RNNs, CNNs, and Transformers) in recognizing spoken language.

---

### Skills Applied

- Statistical language modeling (n-grams, Hidden Markov Models)  

- Deep learning architectures for sequence modeling (RNNs, LSTMs, CNNs, Transformers)  

- Feature extraction from speech signals (MFCCs, spectrogram analysis)  

- Comparative evaluation of classical vs. modern speech recognition methods  

- Literature synthesis in linguistics and machine learning applications  

---

### Dataset

- Review-based project with reference to benchmark datasets in speech recognition (e.g., TIMIT, LibriSpeech)  

- Linguistic corpora analyzed for phoneme-level and word-level recognition  

---

### Methodology

- Reviewed and analyzed machine learning models applied to speech recognition tasks  

- Compared traditional statistical methods:

  - N-gram language models  

  - Hidden Markov Models (HMMs)  

- With deep learning approaches:

  - Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) models  

  - Convolutional Neural Networks (CNNs) for spectrogram analysis  

  - Transformer-based models for state-of-the-art performance  

- Assessed trade-offs between interpretability, accuracy, and computational complexity  

- Discussed applications in linguistics, phonetics, and natural language processing  

---

### Tools & Technologies

- Programming Languages: Python, R  

- Libraries: `torch`, `tensorflow`, `scikit-learn`, `numpy`, `pandas`, `matplotlib`  

- Speech Features: MFCCs, spectrograms, phoneme labeling  

- Software: Jupyter Notebook, RStudio  

---

### Results & Evaluation

- Traditional methods (HMMs + n-grams): Efficient for smaller datasets, interpretable, but limited accuracy on large vocabulary tasks  

- Deep learning methods (RNNs, LSTMs, CNNs): Improved handling of temporal dependencies, stronger accuracy in continuous speech tasks  

- Transformers: Achieved state-of-the-art recognition accuracy, outperforming RNN-based models, especially in large-scale corpora  

- Highlighted the balance between linguistic interpretability and black-box performance in deep models  

---

### Challenges & Learning

- Addressed the complexity of aligning linguistic theory with statistical models  

- Computational demands of training deep neural networks for speech recognition  

- Trade-offs between model interpretability and predictive performance  

- Strengthened expertise in both traditional NLP pipelines and modern end-to-end speech systems  

---

### Contribution

- Team Members: Dawson Damuth and Daniel Viola

- My Role:  

  - Conducted comparative literature review across classical and deep learning models  

  - Analyzed linguistic underpinnings of speech recognition approaches  

  - Synthesized insights into challenges and opportunities for future research  

---

### References

- Graves, A., Mohamed, A., & Hinton, G. (2013). Speech Recognition with Deep Recurrent Neural Networks. ICASSP.  

- Vaswani, A., et al. (2017). Attention Is All You Need. NeurIPS.  

- Rabiner, L. (1989). A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. Proceedings of the IEEE.  
